{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文件\n",
    "import re\n",
    "def readF(path,encode):\n",
    "    file = open(path,encoding=encode)\n",
    "    txt = file.read()\n",
    "    file.close()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pre_txt(txt):\n",
    "    # 去除日期\n",
    "    # 全角半角\n",
    "    rstring = ''\n",
    "    for uchar in txt:\n",
    "        inside_code = ord(uchar)\n",
    "        if inside_code == 12288:                                #全角空格直接转换\n",
    "            inside_code = 32\n",
    "        elif (inside_code >= 65281 and inside_code <= 65374):   #全角字符（除空格）根据关系转化\n",
    "            inside_code -= 65248\n",
    "        rstring += chr(inside_code)\n",
    "        \n",
    "    txt = rstring\n",
    "    # 去除日期\n",
    "    txt = re.sub(' *[0-9]*-[0-9]*-[0-9]*-[0-9]* */m','',txt)\n",
    "\n",
    "    # 去除标点\n",
    "    txt = re.sub('—*','',txt)\n",
    "    txt = re.sub('……*','',txt)\n",
    "    txt = re.sub('.?/w','',txt)\n",
    "    txt = re.sub('\\n','',txt)\n",
    "    txt = re.sub('/[A-Za-z]','/',txt)\n",
    "    # 去除[]nt\n",
    "    txt = re.sub('(\\[)','',txt)\n",
    "    txt = re.sub('(\\])','',txt)\n",
    "    txt = re.sub('[A-Za-z]*','',txt)\n",
    "    \n",
    "    txt = re.sub(' *','',txt)\n",
    "    txt = re.sub('\\s*','',txt)\n",
    "    return txt\n",
    "    # print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_write(txt_list,path,encode):\n",
    "    with open(path,'w',encoding=encode) as f:\n",
    "        for iter in txt_list:\n",
    "            f.write(iter+'\\n')\n",
    "        f.close()\n",
    "\t    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dic_List(txt):\n",
    "    txt_list = []\n",
    "    txt_list = re.split('/',txt)\n",
    "    f_write(txt_list,\"词表.txt\",'utf-8')\n",
    "    print('总词数: ' + str(len(txt_list)))\n",
    "    return txt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字典切片 用于测试\n",
    "def dict_slice(adict, start, end):\n",
    "    keys = adict.keys()\n",
    "    dict_slice = {}\n",
    "    for k in list(keys)[start:end]:\n",
    "        dict_slice[k] = adict[k]\n",
    "    return dict_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TypeAndToken(txt_list):\n",
    "    dit = {}\n",
    "    for iter in txt_list:\n",
    "        if iter in dit:\n",
    "            dit[iter] = dit[iter] + 1\n",
    "        else:\n",
    "            dit[iter] = 1\n",
    "    # 按照value 排序\n",
    "    dit_sort = sorted(dit.items(), key = lambda kv:(kv[1], kv[0]))\n",
    "    \n",
    "    # dict_slice(dit,1,10)\n",
    "    print('不同词的个数：' + str(len(dit)))\n",
    "    # print (dit_sort[20:40])\n",
    "    return len(txt_list),dit_sort,dit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary():\n",
    "    txt = readF(r'./199801.txt',\"gbk\")\n",
    "    txt = Pre_txt(txt)\n",
    "    dic_list = Dic_List(txt)\n",
    "    return TypeAndToken(dic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Max_match(txt,dit,max_len):\n",
    "    ans_str = \"\"\n",
    "    while len(txt) > 0:\n",
    "        cur = max_len\n",
    "        while cur != 1:\n",
    "            if txt[0:cur] in dit:\n",
    "                ans_str += txt[0:cur]+\"/ \"\n",
    "                txt = txt[cur:]\n",
    "                break    \n",
    "            else:\n",
    "                cur = cur -1\n",
    "        if(cur == 1):\n",
    "            ans_str += txt[cur - 1] +\"/ \"\n",
    "            txt = txt [cur:]\n",
    "\n",
    "    return ans_str\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评测\n",
    "def Recall(test_list,out_list):\n",
    "    cnt = 0\n",
    "    for iter in out_list:\n",
    "        if iter in test_list:\n",
    "            cnt += 1\n",
    "    return cnt/len(test_list)\n",
    "    \n",
    "def Precision(test_list,out_list):\n",
    "    cnt = 0\n",
    "    for iter in out_list:\n",
    "        if iter in test_list:\n",
    "            cnt += 1\n",
    "    return cnt/len(out_list)\n",
    "\n",
    "def F_measure(test_list,out_list):\n",
    "    recal = Recall(test_list,out_list)\n",
    "    precision = Precision(test_list,out_list)\n",
    "    if recal + precision != 0:\n",
    "        return 2 * recal * precision / (recal + precision)\n",
    "    else:\n",
    "        return 2 * recal * precision / 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    total_num,sorted_list,dit= vocabulary()\n",
    "    with open('TypeAndToken.txt','w',encoding='utf-8') as f:\n",
    "        for iter in sorted_list:\n",
    "            f.write(iter[0] +' ' + str(iter[1]) + ' ' + str(iter[1]/total_num) +'\\n')\n",
    "        f.close()\n",
    "    max_len = max(map(len,dit))\n",
    "    print(sorted_list[-10:])\n",
    "    print(max_len)\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d621190d5083409746c54d9e149f68a4223aa9077d6576c6b562ae4740a46d89"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
